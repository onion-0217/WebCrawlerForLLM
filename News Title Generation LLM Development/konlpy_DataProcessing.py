import pandas as pd
from konlpy.tag import Okt
import re
import os
import glob

# ==========================================
# 1. ì„¤ì • ë° íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================================
# ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œì™€ íŒŒì¼ íŒ¨í„´
DATA_DIR = "naver_news_data"
FILE_PATTERN = os.path.join(DATA_DIR, "naver_news_*.csv")
OUTPUT_FILE = "train_style_data.txt"

# íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ë“¤ì„ ëª¨ë‘ ì°¾ì•„ì„œ ì •ë ¬ (202201 -> 202512 ìˆœì„œëŒ€ë¡œ)
all_files = sorted(glob.glob(FILE_PATTERN))

if not all_files:
    print(f"âŒ ì˜¤ë¥˜: '{DATA_DIR}' í´ë” ì•ˆì— 'naver_news_'ë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
    exit()

print(f"ğŸ“‚ ì´ {len(all_files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
print(f"   - ì²« ë²ˆì§¸ íŒŒì¼: {os.path.basename(all_files[0])}")
print(f"   - ë§ˆì§€ë§‰ íŒŒì¼: {os.path.basename(all_files[-1])}")

# í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
okt = Okt()
training_data = []

print("\nğŸš€ ëŒ€ê·œëª¨ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

# ==========================================
# 2. ëª¨ë“  íŒŒì¼ì„ ìˆœíšŒí•˜ë©° ë°ì´í„° ì •ì œ
# ==========================================
total_articles = 0  # ì´ ê¸°ì‚¬ ê°œìˆ˜ ì¹´ìš´íŠ¸ìš©

for i, file_path in enumerate(all_files):
    filename = os.path.basename(file_path)
    print(f"[{i + 1}/{len(all_files)}] '{filename}' ì²˜ë¦¬ ì¤‘...", end=" ")

    try:
        # csv íŒŒì¼ ì½ê¸°
        df = pd.read_csv(file_path)

        # ê° ê¸°ì‚¬ë³„ ì²˜ë¦¬
        current_file_count = 0
        for index, row in df.iterrows():
            try:
                raw_title = str(row['title'])
                press = str(row['press'])

                # [Re ëª¨ë“ˆ] íŠ¹ìˆ˜ë¬¸ì ë° ë§ë¨¸ë¦¬ ì²­ì†Œ
                clean_title = re.sub(r'\[.*?\]|\(.*?\)|\<.*?\>', '', raw_title)
                clean_title = clean_title.strip()

                # 1. ëª…ì‚¬ ì¶”ì¶œ
                nouns = okt.nouns(clean_title)

                # 2. í•œ ê¸€ì ì œê±° (í•„í„°ë§)
                filtered_nouns = [n for n in nouns if len(n) > 1]

                # 3. í•„í„°ë§ëœ ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                if not filtered_nouns:
                    continue

                # 4. í‚¤ì›Œë“œ ì¡°í•© (í•„í„°ë§ëœ ëª…ì‚¬ ì‚¬ìš©)
                keywords = ", ".join(filtered_nouns[:3])

                # [í•™ìŠµ ë°ì´í„° í¬ë§·]
                formatted_text = f"[{press}] {keywords}: {clean_title} </s>"

                training_data.append(formatted_text)
                current_file_count += 1

            except Exception:
                continue

        total_articles += current_file_count
        print(f"âœ… ì™„ë£Œ ({current_file_count}ê°œ ì¶”ì¶œ)")

    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

# ==========================================
# 3. ê²°ê³¼ ì €ì¥í•˜ê¸°
# ==========================================
print("\n" + "="*50)
print("ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘...")

with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    for line in training_data:
        f.write(line + "\n")

print(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
print(f"ğŸ“Š ì´ ì²˜ë¦¬ëœ íŒŒì¼: {len(all_files)}ê°œ")
print(f"ğŸ“ ìƒì„±ëœ í•™ìŠµ ë¬¸ì¥: {total_articles}ê°œ")
print(f"íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(OUTPUT_FILE)}")
print("="*50)