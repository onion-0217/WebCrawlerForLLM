import pandas as pd
from konlpy.tag import Okt
import re
import os
import glob

# ==========================================
# 1. ì„¤ì • ë° íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================================
DATA_DIR = "naver_news_data"
FILE_PATTERN = os.path.join(DATA_DIR, "naver_news_*.csv")
OUTPUT_FILE = "train_style_data.txt"

all_files = sorted(glob.glob(FILE_PATTERN))

if not all_files:
    print(f"âŒ ì˜¤ë¥˜: '{DATA_DIR}' í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

print(f"ğŸ“‚ ì´ {len(all_files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

# í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
okt = Okt()
training_data = []

# ==========================================
# ğŸ”¥ [í•µì‹¬] ë¸”ë™ë¦¬ìŠ¤íŠ¸(ë¶ˆìš©ì–´) ì •ì˜
# ë‰´ìŠ¤ ì œëª©ì— ìì£¼ ë‚˜ì˜¤ì§€ë§Œ, í‚¤ì›Œë“œë¡œëŠ” ì“¸ëª¨ì—†ëŠ” ë‹¨ì–´ë“¤ì…ë‹ˆë‹¤.
# ==========================================
STOP_WORDS = {
    'ì´ë²ˆ', 'ì§€ë‚œ', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ëª¨ë ˆ', 'ê´€ë ¨', 'ëŒ€í•´', 'ê°€ì¥',
    'í†µí•´', 'ìœ„í•´', 'ê²½ìš°', 'ë•Œë¬¸', 'ì •ë„', 'ë¶€ë¶„', 'ì‚¬ì‹¤', 'ì´ì œ',
    'ë‹¤ì‹œ', 'ê³„ì†', 'ì§€ê¸ˆ', 'ë°”ë¡œ', 'ì—­ì‹œ', 'ê·¸ëƒ¥', 'ìì‹ ', 'ì§„ì§œ',
    'ì´í˜•', 'ê·¸ê²ƒ', 'ëˆ„êµ¬', 'ë¬´ì—‡', 'ì–´ë””', 'ì–¸ì œ', 'ìš°ë¦¬', 'ë‹¹ì‹ ',
    'ìµœê·¼', 'ë‹¨ë…', 'ì†ë³´', 'ì¢…í•©', 'ì˜¤ì „', 'ì˜¤í›„', 'í•˜ë£¨', 'ì´í˜•',
    'ëª¨ë‘', 'ë‚´ë…„', 'ì–´ì œ', 'í•˜ë‚˜', 'ë‹¤ì„¯', 'ì—¬ì„¯', 'ì¼ê³±', 'ì—¬ëŸ',
    'ì•„í™‰', 'ì£¼ê°„', 'ë§¤ì¼', 'ì˜¬í•´', 'ë¯¸ë§Œ', 'ë‚´ë…„', 'ì´ìƒ', 'ì‘ë…„',
    'ì´í•˜', 'ì´ˆê³¼', 'ê°œì›”', 'ì•ì„œ', 'ê°œì›”', 'ì´í‹€', 'ì‚¬í˜', 'ë‚˜í˜',
    'ê¸€í”¼'
}

print("\nğŸš€ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ë¶ˆìš©ì–´ ì œê±° í¬í•¨)...")

total_articles = 0

for i, file_path in enumerate(all_files):
    filename = os.path.basename(file_path)
    print(f"[{i + 1}/{len(all_files)}] '{filename}' ì²˜ë¦¬ ì¤‘...", end=" ")

    try:
        df = pd.read_csv(file_path)
        current_file_count = 0

        for index, row in df.iterrows():
            try:
                raw_title = str(row['title'])
                press = str(row['press'])

                # íŠ¹ìˆ˜ë¬¸ì ì²­ì†Œ
                clean_title = re.sub(r'\[.*?\]|\(.*?\)|\<.*?\>', '', raw_title)
                clean_title = clean_title.strip()

                # ëª…ì‚¬ ì¶”ì¶œ
                nouns = okt.nouns(clean_title)

                # 1. ë‘ ê¸€ì ì´ìƒì´ì–´ì•¼ í•¨ (len > 1)
                # 2. ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì—†ì–´ì•¼ í•¨ (not in STOP_WORDS)
                filtered_nouns = [
                    n for n in nouns
                    if len(n) > 1 and n not in STOP_WORDS
                ]

                # í•„í„°ë§ í›„ ë‚¨ì€ ê²Œ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
                if not filtered_nouns:
                    continue

                # í‚¤ì›Œë“œ ì¡°í•© (ìµœëŒ€ 3ê°œ)
                keywords = ", ".join(filtered_nouns[:3])

                formatted_text = f"[{press}] {keywords}: {clean_title} </s>"
                training_data.append(formatted_text)
                current_file_count += 1

            except Exception:
                continue

        total_articles += current_file_count
        print(f"âœ… ì™„ë£Œ ({current_file_count}ê°œ)")

    except Exception as e:
        print(f"âŒ ì‹¤íŒ¨: {e}")

# ì €ì¥
with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    for line in training_data:
        f.write(line + "\n")

print("\n" + "=" * 50)
print(f"ğŸ‰ ì‘ì—… ì™„ë£Œ! ì´ {total_articles}ê°œ ë¬¸ì¥ ìƒì„±")
print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {OUTPUT_FILE}")
print("=" * 50)